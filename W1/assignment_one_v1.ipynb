{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment one \n",
    "### Language Analytics\n",
    "February 2021\n",
    "\n",
    "_Marie Damsgaard Mortensen_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic scripting with Python__\n",
    "\n",
    "Using the corpus called 100-english-novels found on the cds-language GitHub repo, write a Python programme which does the following:\n",
    "\n",
    "- Calculate the total word count for each novel\n",
    "- Calculate the total number of unique words for each novel\n",
    "- Save result as a single file consisting of three columns: filename, total_words, unique_words\n",
    "\n",
    "__General instructions__\n",
    "\n",
    "- For this exercise, you can upload either a standalone script OR a Jupyter Notebook\n",
    "- Save your script as word_counts.py OR word_counts.ipynb\n",
    "- You can either upload the script/notebook here or push to GitHub and include a link - or both!\n",
    "- Your code should be clearly documented in a way that allows others to easily follow the structure of your script.\n",
    "- Similarly, remember to use descriptive variable names! A name like word_count is more readable than wcnt.\n",
    "\n",
    "__Purpose__\n",
    "\n",
    "This assignment is designed to test that you have a understanding of:\n",
    "\n",
    "1. how to structure, document, and share a Python script;\n",
    "2. how to effectively make use of native Python data structures, functions, and flow control;\n",
    "3. how to load, save, and process text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing modules and using os to specify the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"..\", \"data\", \"100_english_novels\", \"corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/100_english_novels/corpus'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking my path if it looks correct\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list to save information there\n",
    "file_name = []\n",
    "total_words = []\n",
    "unique_words = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have made a loop that reads every file and saves filename, total number of words in every file and amount of unique words.\n",
    "\n",
    "The first word _for_ instantiates the loop that performs several actions on each of the filenames found in the path. Before I perform specific actions on each of the files, Path from _pathlib_ creates a concrete path with all the text files in data_path that we want to use. \n",
    "\n",
    "Afterwards, the specific text file is saved in a variable with file.read(). This variable is then split up at every point of a whitespace meaning that words are seperated and are now each a variable in a list called split_text. \n",
    "\n",
    "The length of split_text is appended to the list mentioned in the chunk above and is saved here. The same goes for the filename in question. \n",
    "\n",
    "To save the amount of unique words in every novel, the splitted text is made into the _set_ data type where there are no duplicates. By taking the length of this list unique words are counted and appended to the unique_words list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in Path(data_path).glob(\"*.txt\"):\n",
    "    with open(filename, \"r\", encoding = \"utf-8\") as file:\n",
    "        loaded_text = file.read()\n",
    "        \n",
    "        #splitting text whenever there is a whitespace \n",
    "        split_text = loaded_text.split()\n",
    "        total_words.append(len(split_text))\n",
    "        \n",
    "        #filename\n",
    "        file_name.append(filename.name)\n",
    "        \n",
    "        #unique words\n",
    "        unique_words.append(len(set(split_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is time to make the three lists file_name, total_words and unique_words into one dataframe. Using pandas DataFrame function, each of the lists are made into columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting lists to make a dataframe\n",
    "novel_info = pd.DataFrame({'filename': file_name, 'total_words': total_words, 'unique_words': unique_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cbronte_Villette_1853.txt</td>\n",
       "      <td>196557</td>\n",
       "      <td>29084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forster_Angels_1905.txt</td>\n",
       "      <td>50477</td>\n",
       "      <td>9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woolf_Lighthouse_1927.txt</td>\n",
       "      <td>70185</td>\n",
       "      <td>11157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meredith_Richmond_1871.txt</td>\n",
       "      <td>214985</td>\n",
       "      <td>28892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stevenson_Treasure_1883.txt</td>\n",
       "      <td>68448</td>\n",
       "      <td>10831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chesterton_Thursday_1908.txt</td>\n",
       "      <td>58299</td>\n",
       "      <td>10385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Burnett_Lord_1886.txt</td>\n",
       "      <td>58698</td>\n",
       "      <td>8131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Braddon_Phantom_1883.txt</td>\n",
       "      <td>180676</td>\n",
       "      <td>22474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Gaskell_Ruth_1855.txt</td>\n",
       "      <td>161797</td>\n",
       "      <td>18148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Kipling_Captains_1896.txt</td>\n",
       "      <td>53467</td>\n",
       "      <td>11709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  total_words  unique_words\n",
       "0      Cbronte_Villette_1853.txt       196557         29084\n",
       "1        Forster_Angels_1905.txt        50477          9464\n",
       "2      Woolf_Lighthouse_1927.txt        70185         11157\n",
       "3     Meredith_Richmond_1871.txt       214985         28892\n",
       "4    Stevenson_Treasure_1883.txt        68448         10831\n",
       "..                           ...          ...           ...\n",
       "95  Chesterton_Thursday_1908.txt        58299         10385\n",
       "96         Burnett_Lord_1886.txt        58698          8131\n",
       "97      Braddon_Phantom_1883.txt       180676         22474\n",
       "98         Gaskell_Ruth_1855.txt       161797         18148\n",
       "99     Kipling_Captains_1896.txt        53467         11709\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the dataframe\n",
    "print(novel_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I'm making a new output folder where the file is saved as .csv. The path is made in the same way as the data-path in the beginning. The function to_csv() saves the file novel_info with the path specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a directory to keep track of output files\n",
    "os.mkdir(\"output_marie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = os.path.join(\"output_marie\", \"novel_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_info.to_csv(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang101",
   "language": "python",
   "name": "lang101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
